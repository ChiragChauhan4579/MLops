{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3KgolQx-ZYN7"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset = datasets.load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uef7HfYWZ1TN"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "mlflow.sklearn.autolog()\n",
        "with mlflow.start_run():\n",
        " clf = LogisticRegression()\n",
        " clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxhrHdrKa00L"
      },
      "source": [
        "The mlflow.sklearn.autolog() instruction enables you to automatically \n",
        "log the experiment in the local directory. It captures the metrics produced by the \n",
        "underlying ML library in use. MLflow Tracking is the module responsible for \n",
        "handling metrics and logs. By default, the metadata of an MLflow run is stored in \n",
        "the local filesystem. \n",
        "\n",
        "The mlruns folder is generated alongside your notebook folder and contains all the \n",
        "experiments executed by your code in the current context.\n",
        "\n",
        "Your experiment is identified as UUID on the preceding sample by \n",
        "46dc6db17fb5471a9a23d45407da680f. At the root of the directory, you have a \n",
        "yaml file named meta.yaml.\n",
        "\n",
        "This is the basic metadata of your experiment, with information including start time, end \n",
        "time, identification of the run (run_id and run_uuid), an assumption of the life cycle \n",
        "stage, and the user who executed the experiment. The settings are basically based on a \n",
        "default run, but provide valuable and readable information regarding your experiment.\n",
        "\n",
        "The model.pkl file contains a serialized version of the model. For a scikit-learn model, \n",
        "there is a binary version of the Python code of the model. Upon autologging, the metrics \n",
        "are leveraged from the underlying machine library in use. The default packaging strategy \n",
        "was based on a conda.yaml file, with the right dependencies to be able to serialize the \n",
        "model.\n",
        "\n",
        "The MLmodel file is the main definition of the project from an MLflow project with \n",
        "information related to how to run inference on the current model.\n",
        "\n",
        "The metrics folder contains the training score value of this particular run of the training \n",
        "process, which can be used to benchmark the model with further model improvements \n",
        "down the line.\n",
        "\n",
        "The params folder on the first listing of folders contains the default parameters of the \n",
        "logistic regression model, with the different default possibilities listed transparently and \n",
        "stored automatically."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Iris-classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
